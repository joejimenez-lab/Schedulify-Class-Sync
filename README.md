# Schedulify-Class-Sync
# Schedule OCR â†’ Calendar (Localâ€‘first)

Turn class schedule screenshots (e.g., Cal State LA portal) into clean calendar events. Users upload an image, review extracted classes, download a single `.ics`, or oneâ€‘click import to Google Calendar.

**Localâ€‘first & lowâ€‘cost:** Uses free OCR (Tesseract) and an optional **local LLM via Ollama** for robust parsing. No cloud required.

---

## âœ¨ Features (MVP)

* Upload **PNG/JPG/PDF** schedule screenshots
* **OCR â†’ structured classes** (multiâ€‘class, lecture/lab supported)
* Perâ€‘row **days, times, start/end dates** (term range autodetect when present)
* **Review & edit** in a simple table (highlight missing fields)
* **Export `.ics`** with recurring events (BYDAY, UNTIL)
* **Optional:** Add to **Google Calendar** via OAuth (can be toggled off)
* **Local** LLM normalization with **Ollama** (e.g., `llama3.1`, `mistral`) for messy layouts

---

## ğŸ—ï¸ Architecture

```
frontend (Next.js/React/Tailwind)
   â””â”€â”€ Upload â†’ Show table â†’ Download .ics â†’ (Optional) Google import
backend (FastAPI, Python)
   â”œâ”€â”€ ocr: Tesseract (pytesseract) + OpenCV preprocessing
   â”œâ”€â”€ parse: heuristics + (optional) LLM normalize via Ollama
   â”œâ”€â”€ calendar: icalendar to build .ics
   â””â”€â”€ google: OAuth + Calendar API (optional route)
```

**Data contract:**

```json
{
  "events": [
    {
      "title": "CIS 2840 - Data Structures",
      "days": ["MO","WE"],
      "start_time": "13:00",
      "end_time": "14:30",
      "start_date": "2025-01-21",
      "end_date": "2025-05-16",
      "location": "Salazar Hall 232",
      "instructor": "M. Alvarez",
      "notes": "Section 01",
      "termLabel": "Spring 2025"
    }
  ],
  "timezone": "America/Los_Angeles"
}
```

---

## ğŸ“ Folder structure (start here)

```
schedule-ocr/
â”œâ”€ README.md
â”œâ”€ .env.example
â”œâ”€ backend/
â”‚  â”œâ”€ pyproject.toml
â”‚  â”œâ”€ uvicorn.ini
â”‚  â””â”€ app/
â”‚     â”œâ”€ main.py              # FastAPI app + routes
â”‚     â”œâ”€ ocr.py               # OpenCV + Tesseract OCR
â”‚     â”œâ”€ parser.py            # regex/layout heuristics
â”‚     â”œâ”€ llm_ollama.py        # local LLM normalization
â”‚     â”œâ”€ schema.py            # Pydantic models
â”‚     â”œâ”€ ics.py               # ICS generator
â”‚     â””â”€ google.py            # (optional) OAuth + event creation
â”œâ”€ frontend/
â”‚  â”œâ”€ package.json
â”‚  â”œâ”€ next.config.js
â”‚  â”œâ”€ app/
â”‚  â”‚  â”œâ”€ page.tsx            # upload + table + actions
â”‚  â”‚  â””â”€ api/
â”‚  â”‚     â””â”€ google/          # (optional) OAuth handlers
â”‚  â””â”€ styles/
â”‚     â””â”€ globals.css
â”œâ”€ docs/
â”‚  â””â”€ samples/               # sample screenshots for testing
â””â”€ scripts/
   â””â”€ dev.sh                 # convenience dev runner
```

Create the folders/files above first; contents below.

---

## ğŸ”§ Prerequisites

* **Python 3.11+**
* **Node 18+ / PNPM or NPM**
* **Tesseract OCR**

  * macOS: `brew install tesseract`
  * Ubuntu: `sudo apt-get install tesseract-ocr`
* **Ollama** (optional for AI normalization): [https://ollama.com](https://ollama.com)

  * Example models: `ollama pull llama3.1` or `ollama pull mistral`

> If skipping Google import, you donâ€™t need any Google Cloud setup.

---

## ğŸ§ª Quick start (dev)

```bash
# 1) Backend
cd backend
python -m venv .venv && source .venv/bin/activate
pip install -U pip
pip install -e .            # from pyproject.toml
# Run
uvicorn app.main:app --reload --port 8000

# 2) Frontend
cd ../frontend
pnpm install  # or npm install
pnpm dev      # runs at http://localhost:3000
```

Open [http://localhost:3000](http://localhost:3000) and try a sample image from `docs/samples/`.

---

## ğŸ”‘ Environment variables

Create `.env` files from the example:

**Root `.env.example`**

```
# Frontend â†’ Backend
NEXT_PUBLIC_API_BASE=http://localhost:8000
DEFAULT_TIMEZONE=America/Los_Angeles

# Optional Google integration (Frontend API routes)
GOOGLE_CLIENT_ID=
GOOGLE_CLIENT_SECRET=
NEXT_PUBLIC_BASE_URL=http://localhost:3000

# Ollama (local LLM)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.1
```

Copy as needed to `frontend/.env.local` and backend uses `python-dotenv` (already handled in code skeleton).

---

## ğŸ”’ Privacy & cost

* Processing is local; images arenâ€™t stored by default. No perâ€‘request cloud fees.
* LLM costs are **$0** with Ollama. (CPU works; GPU speeds up inference.)

---

## ğŸ›£ï¸ Roadmap

* Tableâ€‘grid detector (column bucketing for Monâ€“Fri grids)
* Visual overlays of detected blocks (confidence)
* Term presets (Fall/Spring templates)
* Idempotent Google imports (skip duplicates)

---

## ğŸ“ License

MIT (change as you prefer).

---

## ğŸ™Œ Contributing

PRs welcome! Share sample screenshots in `docs/samples/` to improve parsers.
